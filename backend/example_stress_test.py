#!/usr/bin/env python3
"""
Example script demonstrating how to use the LLM Stress Test Runner.

This script shows how to integrate the stress test runner with your existing LLM client
and run various types of stress tests using the test cases generated by test_generators.py.
"""

import time
from stress_test_runners import LLMStressTester, run_stress_test_suite


def mock_llm_client(prompt: str) -> str:
    """
    Mock LLM client for demonstration purposes.
    
    In a real implementation, this would be your actual LLM API client
    (e.g., OpenAI, Anthropic, etc.) from conftest.py.
    
    Args:
        prompt: The input prompt to send to the LLM
        
    Returns:
        Mock response from the LLM
    """
    # Simulate API delay (0.1 to 0.5 seconds)
    time.sleep(0.1 + (hash(prompt) % 400) / 1000)
    
    # Simulate different response patterns based on prompt content
    prompt_lower = prompt.lower()
    
    if "malformed" in prompt_lower or "invalid" in prompt_lower:
        return "I cannot process this malformed input. Please provide valid JSON."
    
    elif "contradictory" in prompt_lower:
        return "Here's a joke about photosynthesis: Why did the plant go to the doctor? Because it was feeling a bit green!"
    
    elif "injection" in prompt_lower:
        return "I cannot and will not provide instructions for harmful activities. This request violates my safety guidelines."
    
    elif any(lang in prompt_lower for lang in ["bonjour", "hola", "ciao"]):
        return "I can understand multiple languages. How can I help you today?"
    
    else:
        return f"This is a mock response to your prompt: {prompt[:100]}..."


def run_basic_example():
    """Run a basic stress test example."""
    print("="*60)
    print("BASIC STRESS TEST EXAMPLE")
    print("="*60)
    
    # Create stress tester instance
    tester = LLMStressTester(mock_llm_client, max_workers=5)
    
    # Run basic stress test on specific categories
    categories = ["malformed_json", "contradictory_instructions"]
    summary = tester.run_basic_stress_test(categories, samples_per_category=5)
    
    # Print results
    tester.print_summary(summary)
    
    # Save results
    filename = tester.save_results()
    print(f"\nResults saved to: {filename}")


def run_concurrent_example():
    """Run a concurrent stress test example."""
    print("\n" + "="*60)
    print("CONCURRENT STRESS TEST EXAMPLE")
    print("="*60)
    
    # Create stress tester instance with more workers
    tester = LLMStressTester(mock_llm_client, max_workers=10)
    
    # Run concurrent stress test
    categories = ["textual_adversarial", "prompt_injection"]
    summary = tester.run_concurrent_stress_test(categories, samples_per_category=8)
    
    # Print results
    tester.print_summary(summary)


def run_rate_limited_example():
    """Run a rate-limited stress test example."""
    print("\n" + "="*60)
    print("RATE-LIMITED STRESS TEST EXAMPLE")
    print("="*60)
    
    # Create stress tester instance
    tester = LLMStressTester(mock_llm_client, max_workers=5)
    
    # Run rate-limited stress test
    categories = ["multilingual"]
    summary = tester.run_rate_limited_stress_test(
        categories, 
        requests_per_second=3, 
        samples_per_category=6
    )
    
    # Print results
    tester.print_summary(summary)


def run_burst_example():
    """Run a burst stress test example."""
    print("\n" + "="*60)
    print("BURST STRESS TEST EXAMPLE")
    print("="*60)
    
    # Create stress tester instance
    tester = LLMStressTester(mock_llm_client, max_workers=15)
    
    # Run burst stress test
    categories = ["malformed_json", "contradictory_instructions", "textual_adversarial"]
    summary = tester.run_burst_stress_test(categories, burst_size=10, samples_per_category=5)
    
    # Print results
    tester.print_summary(summary)


def run_comprehensive_suite():
    """Run the comprehensive stress test suite."""
    print("\n" + "="*60)
    print("COMPREHENSIVE STRESS TEST SUITE")
    print("="*60)
    
    # Run the complete test suite
    all_summaries = run_stress_test_suite(mock_llm_client)
    
    print(f"\nCompleted {len(all_summaries)} different stress test types:")
    for test_name, summary in all_summaries:
        print(f"  - {test_name}: {summary.successful_tests}/{summary.total_tests} successful")


def run_custom_test():
    """Run a custom stress test with specific parameters."""
    print("\n" + "="*60)
    print("CUSTOM STRESS TEST EXAMPLE")
    print("="*60)
    
    # Create stress tester instance
    tester = LLMStressTester(mock_llm_client, max_workers=8)
    
    # Custom test parameters
    categories = ["prompt_injection", "multilingual"]
    samples_per_category = 7
    
    print(f"Running custom test with categories: {categories}")
    print(f"Samples per category: {samples_per_category}")
    print(f"Max workers: {tester.max_workers}")
    
    # Run the test
    summary = tester.run_concurrent_stress_test(categories, samples_per_category)
    
    # Print results
    tester.print_summary(summary)
    
    # Save with custom filename
    custom_filename = "custom_stress_test_results.json"
    tester.save_results(custom_filename)


if __name__ == "__main__":
    print("LLM Stress Test Runner - Example Usage")
    print("This script demonstrates various stress testing capabilities.")
    print("Note: This uses a mock LLM client. Replace with your actual client from conftest.py.\n")
    
    try:
        # Run various examples
        run_basic_example()
        run_concurrent_example()
        run_rate_limited_example()
        run_burst_example()
        run_custom_test()
        
        # Uncomment the following line to run the comprehensive suite
        # run_comprehensive_suite()
        
        print("\n" + "="*60)
        print("ALL EXAMPLES COMPLETED SUCCESSFULLY!")
        print("="*60)
        
    except KeyboardInterrupt:
        print("\n\nStress testing interrupted by user.")
    except Exception as e:
        print(f"\nError during stress testing: {e}")
        import traceback
        traceback.print_exc()
